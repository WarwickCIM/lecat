---
title: "Console"
output: html_document
---

LE-CAT is an R package. All of functionality available in the shiny app are available via the R console. Below we go through how to carry out an analysis using the console.

LE-CAT requires three excel files for input:

* __Corpus__. The text to be searched. Columns need column names and these must be unique
* __Lexicon__. The query terms you wish to search for and the associated categories and types.
* __Lookup table__. LE-CAT allows you to search for different types in different columns of the corpus.

## Example data

The shiny app allows you to download an example lexicon, corpus and lookup table

```{r}
require(lecat)
example_lexicon <- dplyr::tribble(
  ~Type,          ~Category,     ~Query,           ~Query1,        ~Query2,
  'technology',   'Apple',       'iphone',         'iPad',         'imac',
  'influencers',  'CIM',         'Noortje Marres', 'James Tripp',  ''
)

example_corpus <- dplyr::tribble(
  ~title,                           ~description,
  'James Tripp talks about LE-CAT', 'In this iphone and ipad delivered lecture James talks about a new tool.',
  'Noortje Marres Interview',       'An interesting interview',
  'New iphone',                     'Apple has launched a series of iphones, ipads and imacs.'
)

example_lookup_table <- dplyr::tribble(
  ~Type, ~Column,
  'technology', 'description',
  'influencers', 'title'
)
 
```

The corpus is a series of entries (e.g., Tweets, YouTube descriptions, etc.). In the example corpus, there is a title and description column.

| title | description |
|-------|-------------|
| James Tripp talks about LE-CAT | In this iphone and ipad delivered lecture James talks about a new tool. |
| Noortje Marres interview | An interesting interview |
| New iphone | Apple has launched a series of iphones, ipads and imacs. |

The lexicon contains the queries you wish to look for, the categories associated with the queries and the type of category. The lexicon is in a wide form.

| Type       | Category | Query    | Query1    | Query2 |
| ---------- | -------- | -------- | --------- | ------ |
| technology | Apple | iphone | iPad | imac  |
| influencers | CIM | Noortje Marres | James Tripp | |

The above lexicon will instruct LE-CAT to search for the terms iphone, iPad, imac, Noortje Marres and James Tripp. The presence of the queries iphone, iPad and imac indicate that the Category Apple is present in the corpus.

In the example data, we want to search for queries associateed with Apple in the descriptions column of the corpus and the CIM queries in the title column of the corpus. The lookup table tells LE-CAT which column of the corpus to search in.

| Type       | Column |
| ---------- | -------- |
| technology | description | 
| influencers | title | 

Which tells LE-CAT to:

* search for technology queries in the description column of the corpus
* search for influencers queries in the title column of the corpus

## Parse lexicon

A wide format lexicon (as shown in the example data) is structure I find easier to teach with. This wide format needs to be changed to a long format (wish one query per row) using the parse_lexicon function.

```{r}
lexicon <- parse_lexicon(example_lexicon)
lexicon
```

## Query searching

LE-CAT searches for terms in the corpus text. You may wish to specify a
different search column for each Type. The search column for each type
is specified in the lookup table.

To carry out your search of the corpus, pass the long form lexicon, the
search data frame and corpus to the run\_lecat\_analysis function.

```{r, message = FALSE, warning = FALSE, results = FALSE}
lecat_result <- run_lecat_analysis(lexicon = lexicon,
                                   corpus = example_corpus,
                                   searches = example_lookup_table,
                                   regex_expression = '\\Wquery\\W')
```

Note that you can pass your own regex expression. The function replaces
the text ‘query’ with the relevent search query. The above searches for
cases where there are non-word characters (e.g., spaces or periods)
located on either side of the search query.

The query result is a table like the below

| Type       | Category | Query   | Column_examined | V1 | V2 | V3 |
| ---------- | -------- | ------- | ---------------- | --- | --- | ---|
| technology | Apple | iphone | description      | 1   | 0   | 0 |
| technology | Apple | ipad   | description      | 1   | 0   | 0 |
| technology | Apple | imac   | description      | 0   | 0   | 0 |
| influencers | CIM | noortje marres | title      | 0   | 0   | 0 |
| influencers | CIM | James Tripp    | title      | 0   | 0   | 0 |

where V1 and V2 are the ids specified above for each entry in the
corpus.

## Diagnostics

The LE-CAT raw count data shown above may be hard for one to process.
The above can be summarised into a diagnostic file using the
create\_unique\_total\_diagnostics function

```{r, message = FALSE, warning = FALSE, results = FALSE}
diagnostics <- create_unique_total_diagnostics(lecat_result)
```

to create a table like
so

| Type            | Category                    | Queries                                         | Column_examined |
| --------------- | --------------------------- | ----------------------------------------------- | ---------------- |
| technology(2,1) | Apple(2,1) | iphone(1,1) ipad(1,1) imac(0,0) | description      |
| influencers(0,0) | CIM(0,0) | noortje marres(0,0) james tripp(0,0) | title      |

where the first number in the brackets is the total occurance and second
is the number of corpus rows each
Type, Category and Query occur in.

## Cooccurance

You may calculate the cooccurance of queries (irrespective of the
corresponding Type and Category) using the create\_cooccurrence\_graph
function

```{r, message = FALSE, warning = FALSE, results = FALSE}
cooccurrence <-
  create_cooccurrence_graph(lecat_result = lecat_result,
                            level = 'Query')
```

**Note** Creating the cooccurence graph can take a lot of time depending
on the size of corpus and lexicon.

You can calculate cooccurance based on the categories by changing the
level argument to ‘Category’.

By default the files ‘result.graphml’ and ‘cotable.csv’ are created in
the working directory.

The result.grapml file contains a network of the cooccurences. The Type,
Category and Column\_examined are attributes of the nodes and the weight
of the edges are the cooccurance of the queries. You may view graphml
network graphs using the excellent [Gephi](https://gephi.org) program.
**Note** if you have duplicate edges (where there are edges between
node1-node2 and node2-node1 then select merge first withing Gephi).

The cotable.csv file is a table of the cooccurences. This file can be
loaded into programs such as Excel, LibreOffice or R.

The create\_cooccurrence\_graph function returns a list containing the
cooccurence table as a data frame and the cooccurence network as an
igraph network. The igraph object may be useful as the igraph package
contains many functions for calculating statistics on the generated
netowrk. You may also plot the object in R using the following command:

```{r, message = FALSE, warning = FALSE}
require(igraph)
plot(cooccurrence$graph)
```

and view the cooccurance table like so

```{r, message = FALSE, warning = FALSE, results = FALSE}
cooccurrence$cotable
```
