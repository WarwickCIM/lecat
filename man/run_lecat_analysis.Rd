% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/run_lecat_analysis.R
\name{run_lecat_analysis}
\alias{run_lecat_analysis}
\title{Searches for queries in a corpus using a specific regular expression}
\usage{
run_lecat_analysis(
  lexicon,
  corpus,
  searches,
  id = NaN,
  regex_expression = "(?<=\\\\W|^)query(?=\\\\W|$)",
  inShiny = FALSE,
  case_sensitive = FALSE,
  advanced_mode = FALSE
)
}
\arguments{
\item{lexicon}{Lexicon dataframe as parsed by the \link[lecat]{parse_lexicon} function}

\item{corpus}{Corpus dataframe containing search columns present in the searches dataframe}

\item{searches}{Data frame with the columns 'Type' and 'Column'. Queries in each Type will be located in the corresponding corpus Column}

\item{id}{Column name to use for identifying differing corpus samples (e.g., YouTube video id). Autogenerated if no id is provided.}

\item{regex_expression}{String regular expression defining search pattern. Defaults to searching for the query term with non word characters either side or at the beginning or end of string. Look behind and look ahead impede characters outside the query term to be matched (correctly finds emoji or any other non-word query terms)}

\item{inShiny}{If inShiny is TRUE then shiny based notifications will be shown}

\item{case_sensitive}{If case_sensitive is TRUE then the search will be case sensitive}

\item{advanced_mode}{If advanced_mode is TRUE then the search will not apply a regex, instead it will assume all query terms are well-formed regex patterns (this covers query terms with no regex pattern at all).}
}
\value{
run_lecat_analysis returns a data frame containing the lexicon, the corresponding search column for the query type and the frequency of terms by corpus id
}
\description{
Each corpus element is checked for the presence of a query. The process is repeated for multiple queries. The result is a table of queries and number of matches for each corpus row.
}
